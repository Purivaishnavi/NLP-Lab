{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 29 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "text1 = [\"\"\"Gensim is a free open-source Python library for representing documents as semantic vectors,\n",
    "           as efficiently and painlessly as possible. Gensim is designed \n",
    "           to process raw, unstructured digital texts using unsupervised machine learning algorithms.\"\"\"]\n",
    "\n",
    "tokens1 = [[item for item in line.split()] for line in text1]\n",
    "g_dict1 = corpora.Dictionary(tokens1)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 190 tokens\n",
      "\n",
      "{'already': 0, 'appdata': 1, 'cell_type': 2, 'cells': 3, 'code': 4, 'execution_count': 5, 'gensim': 6, 'hp': 7, 'in': 8, 'lib': 9, 'local': 10, 'metadata': 11, 'name': 12, 'output_type': 13, 'outputs': 14, 'packages': 15, 'programs': 16, 'python': 17, 'requirement': 18, 'satisfied': 19, 'site': 20, 'stdout': 21, 'stream': 22, 'text': 23, 'users': 24, 'numpy': 25, 'from': 26, 'scipy': 27, 'open': 28, 'smart': 29, 'wrapt': 30, 'kernel': 31, 'may': 32, 'need': 33, 'note': 34, 'restart': 35, 'the': 36, 'to': 37, 'updated': 38, 'use': 39, 'you': 40, 'at': 41, 'deprecation': 42, 'egg': 43, 'loading': 44, 'stderr': 45, 'vboxapi': 46, 'py': 47, 'deprecated': 48, 'is': 49, 'pip': 50, 'behaviour': 51, 'change': 52, 'enforce': 53, 'this': 54, 'will': 55, 'for': 56, 'installation': 57, 'package': 58, 'possible': 59, 'replacement': 60, 'be': 61, 'can': 62, 'discussion': 63, 'found': 64, 'github': 65, 'https': 66, 'algorithms': 67, 'com': 68, 'dictionary': 69, 'has': 70, 'install': 71, 'issues': 72, 'pypa': 73, 'source': 74, 'tokens': 75, 'upgrade': 76, 'and': 77, 'as': 78, 'designed': 79, 'digital': 80, 'documents': 81, 'efficiently': 82, 'free': 83, 'learning': 84, 'library': 85, 'machine': 86, 'painlessly': 87, 'corpora': 88, 'import': 89, 'process': 90, 'raw': 91, 'representing': 92, 'semantic': 93, 'texts': 94, 'unstructured': 95, 'unsupervised': 96, 'using': 97, 'vectors': 98, 'item': 99, 'line': 100, 'g_dict': 101, 'split': 102, 'len': 103, 'print': 104, 'str': 105, 'directory': 106, 'ename': 107, 'errno': 108, 'evalue': 109, 'file': 110, 'id': 111, 'no': 112, 'or': 113, 'sample_text': 114, 'such': 115, 'token': 116, 'call': 117, 'cell': 118, 'error': 119, 'last': 120, 'mfrom': 121, 'mgensim': 122, 'min': 123, 'most': 124, 'recent': 125, 'traceback': 126, 'txt': 127, 'mimport': 128, 'mopen': 129, 'msample_text': 130, 'mutils': 131, 'mencoding': 132, 'mfor': 133, 'mutf': 134, 'mread': 135, 'msplit': 136, 'core': 137, 'ipython': 138, 'mc': 139, 'args': 140, 'by': 141, 'crash': 142, 'default': 143, 'fd': 144, 'it': 145, 'kwargs': 146, 'let': 147, 'likely': 148, 'm_modified_open': 149, 'mas': 150, 'mf': 151, 'mfile': 152, 'mif': 153, 'mipython': 154, 'mraise': 155, 'mt': 156, 'mvalueerror': 157, 'won': 158, 'are': 159, 'builtins': 160, 'doing': 161, 'if': 162, 'know': 163, 'myou': 164, 'what': 165, 'margs': 166, 'mio_open': 167, 'mkwargs': 168, 'mreturn': 169, 'nlp': 170, 'utils': 171, 'encoding': 172, 'ipynb': 173, 'utf': 174, 'read': 175, 'append': 176, 'deacc': 177, 'true': 178, 'codemirror_mode': 179, 'display_name': 180, 'file_extension': 181, 'kernelspec': 182, 'language': 183, 'language_info': 184, 'version': 185, 'mimetype': 186, 'pygments_lexer': 187, 'nbformat': 188, 'nbformat_minor': 189}\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "\n",
    "text2 = open('nlp2.ipynb', encoding ='utf-8')\n",
    " \n",
    "tokens2 =[]\n",
    "for line in text2.read().split('.'):\n",
    "  tokens2.append(simple_preprocess(line, deacc = True))\n",
    "\n",
    "g_dict2 = corpora.Dictionary(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict2)) + \" tokens\\n\")\n",
    "print(g_dict2.token2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 198 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28, 'already': 29, 'appdata': 30, 'cell_type': 31, 'cells': 32, 'code': 33, 'execution_count': 34, 'gensim': 35, 'hp': 36, 'in': 37, 'lib': 38, 'local': 39, 'metadata': 40, 'name': 41, 'output_type': 42, 'outputs': 43, 'packages': 44, 'programs': 45, 'python': 46, 'requirement': 47, 'satisfied': 48, 'site': 49, 'stdout': 50, 'stream': 51, 'text': 52, 'users': 53, 'numpy': 54, 'from': 55, 'scipy': 56, 'open': 57, 'smart': 58, 'wrapt': 59, 'kernel': 60, 'may': 61, 'need': 62, 'note': 63, 'restart': 64, 'the': 65, 'updated': 66, 'use': 67, 'you': 68, 'at': 69, 'deprecation': 70, 'egg': 71, 'loading': 72, 'stderr': 73, 'vboxapi': 74, 'py': 75, 'deprecated': 76, 'pip': 77, 'behaviour': 78, 'change': 79, 'enforce': 80, 'this': 81, 'will': 82, 'installation': 83, 'package': 84, 'possible': 85, 'replacement': 86, 'be': 87, 'can': 88, 'discussion': 89, 'found': 90, 'github': 91, 'https': 92, 'algorithms': 93, 'com': 94, 'dictionary': 95, 'has': 96, 'install': 97, 'issues': 98, 'pypa': 99, 'source': 100, 'tokens': 101, 'upgrade': 102, 'corpora': 103, 'import': 104, 'raw': 105, 'vectors': 106, 'item': 107, 'line': 108, 'g_dict': 109, 'split': 110, 'len': 111, 'print': 112, 'str': 113, 'directory': 114, 'ename': 115, 'errno': 116, 'evalue': 117, 'file': 118, 'id': 119, 'no': 120, 'or': 121, 'sample_text': 122, 'such': 123, 'token': 124, 'call': 125, 'cell': 126, 'error': 127, 'last': 128, 'mfrom': 129, 'mgensim': 130, 'min': 131, 'most': 132, 'recent': 133, 'traceback': 134, 'txt': 135, 'mimport': 136, 'mopen': 137, 'msample_text': 138, 'mutils': 139, 'mencoding': 140, 'mfor': 141, 'mutf': 142, 'mread': 143, 'msplit': 144, 'core': 145, 'ipython': 146, 'mc': 147, 'args': 148, 'by': 149, 'crash': 150, 'default': 151, 'fd': 152, 'it': 153, 'kwargs': 154, 'let': 155, 'likely': 156, 'm_modified_open': 157, 'mas': 158, 'mf': 159, 'mfile': 160, 'mif': 161, 'mipython': 162, 'mraise': 163, 'mt': 164, 'mvalueerror': 165, 'won': 166, 'are': 167, 'builtins': 168, 'doing': 169, 'if': 170, 'know': 171, 'myou': 172, 'what': 173, 'margs': 174, 'mio_open': 175, 'mkwargs': 176, 'mreturn': 177, 'nlp': 178, 'utils': 179, 'encoding': 180, 'ipynb': 181, 'utf': 182, 'read': 183, 'append': 184, 'deacc': 185, 'true': 186, 'codemirror_mode': 187, 'display_name': 188, 'file_extension': 189, 'kernelspec': 190, 'language': 191, 'language_info': 192, 'version': 193, 'mimetype': 194, 'pygments_lexer': 195, 'nbformat': 196, 'nbformat_minor': 197}\n"
     ]
    }
   ],
   "source": [
    "g_dict1.add_documents(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words :  [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\"\n",
    "]\n",
    "\n",
    "# Tokenize the documents\n",
    "texts = [[word for word in document.lower().split()] for document in documents]\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized texts\n",
    "my_dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Convert each document to the Bag of Words format\n",
    "BoW_corpus = [my_dictionary.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abc', 0.404], ['applications', 0.404], ['computer', 0.248], ['for', 0.404], ['human', 0.248], ['interface', 0.248], ['lab', 0.404], ['machine', 0.404], ['computer', 0.274], ['a', 0.446], ['of', 0.345], ['opinion', 0.446], ['response', 0.274], ['survey', 0.446], ['system', 0.173], ['time', 0.274], ['user', 0.173], ['interface', 0.351], ['system', 0.221], ['user', 0.221], ['eps', 0.351], ['management', 0.572], ['the', 0.572], ['human', 0.289], ['of', 0.182], ['system', 0.365], ['eps', 0.289], ['and', 0.471], ['engineering', 0.471], ['testing', 0.471], ['of', 0.157], ['response', 0.249], ['time', 0.249], ['user', 0.157], ['error', 0.407], ['measurement', 0.407], ['perceived', 0.407], ['relation', 0.407], ['to', 0.407]]\n"
     ]
    }
   ],
   "source": [
    "# create TF-IDF model\n",
    "tfIdf = models.TfidfModel(BoW_corpus, smartirs ='ntc')\n",
    " \n",
    "# TF-IDF Word Weight\n",
    "weight_tfidf =[]\n",
    "for doc in tfIdf[BoW_corpus]:\n",
    "  for id, freq in doc:\n",
    "    weight_tfidf.append([my_dictionary[id], np.around(freq, decimals = 3)])\n",
    "print(weight_tfidf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'machine', 'interface', 'for', 'lab', 'abc', 'applications']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Example tokenized documents (list of lists of words)\n",
    "data = [\n",
    "    ['human', 'machine', 'interface', 'for', 'lab', 'abc', 'applications'],\n",
    "    ['a', 'survey', 'of', 'user', 'opinion', 'of', 'computer', 'system'],\n",
    "    ['eps', 'user', 'interface', 'management', 'system'],\n",
    "    ['system', 'and', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
    "    ['relation', 'of', 'user', 'perceived', 'response', 'time', 'to', 'error', 'measurement']\n",
    "]\n",
    "\n",
    "# Create a bigram model\n",
    "bigram_model = Phrases(data, min_count=1, threshold=2)\n",
    "bigram_phraser = Phraser(bigram_model)\n",
    "\n",
    "# Create a trigram model based on the bigram model\n",
    "trigram_model = Phrases(bigram_phraser[data], threshold=10)\n",
    "\n",
    "# Print trigram representation of the first document\n",
    "print(trigram_model[bigram_phraser[data[0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.9221967e+00  1.3565579e-01  1.9997575e+00  9.3454725e-01\n",
      "  7.5550413e-01 -3.8807756e-01  1.2378149e+00 -2.5402749e+00\n",
      " -5.1757425e-01 -7.4277788e-01  4.5480421e-01 -3.3293688e+00\n",
      "  5.7911086e-01  2.3940699e+00 -7.6369047e-03  3.5067430e-01\n",
      " -2.9923122e+00  5.0675255e-01  7.8995186e-01  1.3118814e+00\n",
      " -1.4150051e+00  1.5364408e+00 -2.4870832e+00 -2.1159966e+00\n",
      " -2.1913686e+00  2.3894582e+00 -7.7864629e-01 -1.1784549e+00\n",
      " -4.0701741e-01  1.1801913e+00 -1.9684511e+00  1.0498482e+00\n",
      " -1.5672014e+00 -1.1570655e+00 -1.7990394e+00 -3.3030195e+00\n",
      "  1.4835547e+00  4.0330395e-02  1.2161683e+00  9.3237704e-01\n",
      " -1.9238199e+00  2.5032654e+00 -3.9855960e-01  1.7175914e+00\n",
      "  2.2285049e+00  4.7780421e-01 -1.2321621e+00  1.6171019e+00\n",
      " -3.0706659e-01  3.5415140e-01 -6.0268664e-01  3.9145117e+00\n",
      "  2.1814342e+00 -2.7893344e-01  5.5292261e-01 -4.2738457e+00\n",
      "  1.6682636e+00 -2.1048603e+00 -9.9373889e-01  2.6364996e+00\n",
      " -2.1143903e-03 -9.1688627e-01 -6.4454609e-01  1.6878194e-01\n",
      "  3.7009263e+00 -2.9916914e+00  9.6323580e-02  1.7853014e+00\n",
      " -8.8648356e-02 -4.6884081e-01  1.0125113e+00  2.2910333e+00\n",
      " -1.8050410e+00  2.7170986e-01 -1.9653529e+00 -1.0574633e+00\n",
      " -1.4652744e-01 -4.6702680e-01 -3.3512154e+00 -4.0720091e+00\n",
      "  1.7632232e+00 -4.5469743e-01  1.3783950e+00  2.2774653e+00\n",
      "  1.0132571e+00 -9.9284577e-01 -8.8767785e-01 -3.7969210e+00\n",
      " -8.4278560e-01  3.9634123e+00  1.8189012e+00  2.6286011e+00\n",
      " -1.3323414e+00  1.4913578e+00 -2.2080803e-01 -6.3810992e-01\n",
      "  1.8483503e+00 -1.4049155e+00  8.3621544e-01  1.4022645e+00]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from multiprocessing import cpu_count\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# load the text8 dataset\n",
    "dataset = api.load(\"text8\")\n",
    "\n",
    "# extract a list of words from the dataset\n",
    "data = []\n",
    "for word in dataset:\n",
    "    data.append(word)  # Properly indented\n",
    "\n",
    "# We will split the data into two parts\n",
    "data_1 = data[:1200]  # this is used to train the model\n",
    "data_2 = data[1200:]  # this part will be used to update the model\n",
    "\n",
    "# Training the Word2Vec model\n",
    "w2v_model = Word2Vec(data_1, min_count=0, workers=cpu_count())\n",
    "\n",
    "# word vector for the word \"time\"\n",
    "print(w2v_model.wv['time'])  # Correct way to access word vectors in gensim 4.x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
